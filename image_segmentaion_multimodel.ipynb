{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import segmentation_models as sm\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import keras \n",
    "\n",
    "from keras.utils import normalize\n",
    "from keras.metrics import MeanIoU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resizing images, if needed\n",
    "SIZE_X = 128 \n",
    "SIZE_Y = 128\n",
    "n_classes=2 #Number of classes for segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = []\n",
    "\n",
    "for directory_path in glob.glob(\"128_patches/images/\"):\n",
    "    for img_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
    "        img = cv2.imread(img_path, 1)       \n",
    "        #img = cv2.resize(img, (SIZE_Y, SIZE_X))\n",
    "        train_images.append(img)\n",
    "       \n",
    "#Convert list to array for machine learning processing        \n",
    "train_images = np.array(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_masks = [] \n",
    "for directory_path in glob.glob(\"128_patches/masks/\"):\n",
    "    for mask_path in glob.glob(os.path.join(directory_path, \"*.png\")):\n",
    "        mask = cv2.imread(mask_path, 0)       \n",
    "        #mask = cv2.resize(mask, (SIZE_Y, SIZE_X), interpolation = cv2.INTER_NEAREST)  #Otherwise ground truth changes due to interpolation\n",
    "        train_masks.append(mask)\n",
    "        \n",
    "#Convert list to array for machine learning processing          \n",
    "train_masks = np.array(train_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "n, h, w = train_masks.shape\n",
    "train_masks_reshaped = train_masks.reshape(-1,1)\n",
    "train_masks_reshaped_encoded = labelencoder.fit_transform(train_masks_reshaped)\n",
    "train_masks_encoded_original_shape = train_masks_reshaped_encoded.reshape(n, h, w)\n",
    "\n",
    "np.unique(train_masks_encoded_original_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_masks_input = np.expand_dims(train_masks_encoded_original_shape, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X1, X_test, y1, y_test = train_test_split(train_images, train_masks_input, test_size = 0.10, random_state = 0)\n",
    "\n",
    "#Further split training data t a smaller subset for quick testing of models\n",
    "X_train, X_do_not_use, y_train, y_do_not_use = train_test_split(X1, y1, test_size = 0.5, random_state = 0)\n",
    "\n",
    "print(\"Class values in the dataset are ... \", np.unique(y_train))  # 0 is the background/few unlabeled \n",
    "\n",
    "from keras.utils import to_categorical\n",
    "train_masks_cat = to_categorical(y_train, num_classes=n_classes)\n",
    "y_train_cat = train_masks_cat.reshape((y_train.shape[0], y_train.shape[1], y_train.shape[2], n_classes))\n",
    "\n",
    "\n",
    "\n",
    "test_masks_cat = to_categorical(y_test, num_classes=n_classes)\n",
    "y_test_cat = test_masks_cat.reshape((y_test.shape[0], y_test.shape[1], y_test.shape[2], n_classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes=2\n",
    "activation='softmax'\n",
    "\n",
    "LR = 0.0001\n",
    "optim = keras.optimizers.Adam(LR)\n",
    "\n",
    "# Segmentation models losses can be combined together by '+' and scaled by integer or float factor\n",
    "# set class weights for dice_loss (car: 1.; pedestrian: 2.; background: 0.5;)\n",
    "dice_loss = sm.losses.DiceLoss(class_weights=np.array([0.25, 0.25, 0.25, 0.25])) \n",
    "focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "total_loss = dice_loss + (1 * focal_loss)\n",
    "\n",
    "# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\n",
    "# total_loss = sm.losses.binary_focal_dice_loss # or sm.losses.categorical_focal_dice_loss \n",
    "\n",
    "metrics = [sm.metrics.IOUScore(threshold=0.5), sm.metrics.FScore(threshold=0.5)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE1 = 'resnet34'\n",
    "preprocess_input1 = sm.get_preprocessing(BACKBONE1)\n",
    "\n",
    "# preprocess input\n",
    "X_train1 = preprocess_input1(X_train)\n",
    "X_test1 = preprocess_input1(X_test)\n",
    "\n",
    "# define model\n",
    "model1 = sm.Unet(BACKBONE1, encoder_weights='imagenet', classes=n_classes, activation=activation)\n",
    "\n",
    "# compile keras model with defined optimozer, loss and metrics\n",
    "model1.compile(optim, total_loss, metrics=metrics)\n",
    "\n",
    "#model1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=metrics)\n",
    "\n",
    "print(model1.summary())\n",
    "\n",
    "history1=model1.fit(X_train1, \n",
    "          y_train_cat,\n",
    "          batch_size=8, \n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test1, y_test_cat))\n",
    "\n",
    "\n",
    "model1.save('res34_backbone_50epochs.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE2 = 'inceptionv3'\n",
    "preprocess_input2 = sm.get_preprocessing(BACKBONE2)\n",
    "\n",
    "# preprocess input\n",
    "X_train2 = preprocess_input2(X_train)\n",
    "X_test2 = preprocess_input2(X_test)\n",
    "\n",
    "# define model\n",
    "model2 = sm.Unet(BACKBONE2, encoder_weights='imagenet', classes=n_classes, activation=activation)\n",
    "\n",
    "\n",
    "# compile keras model with defined optimozer, loss and metrics\n",
    "model2.compile(optim, total_loss, metrics)\n",
    "#model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=metrics)\n",
    "\n",
    "\n",
    "print(model2.summary())\n",
    "\n",
    "history2=model2.fit(X_train2, \n",
    "          y_train_cat,\n",
    "          batch_size=8, \n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test2, y_test_cat))\n",
    "\n",
    "\n",
    "model2.save('inceptionv3_backbone_50epochs.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BACKBONE3 = 'vgg16'\n",
    "preprocess_input3 = sm.get_preprocessing(BACKBONE3)\n",
    "\n",
    "# preprocess input\n",
    "X_train3 = preprocess_input3(X_train)\n",
    "X_test3 = preprocess_input3(X_test)\n",
    "\n",
    "\n",
    "# define model\n",
    "model3 = sm.Unet(BACKBONE3, encoder_weights='imagenet', classes=n_classes, activation=activation)\n",
    "\n",
    "# compile keras model with defined optimozer, loss and metrics\n",
    "model3.compile(optim, total_loss, metrics)\n",
    "#model3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=metrics)\n",
    "\n",
    "\n",
    "print(model3.summary())\n",
    "\n",
    "history3=model3.fit(X_train3, \n",
    "          y_train_cat,\n",
    "          batch_size=8, \n",
    "          epochs=50,\n",
    "          verbose=1,\n",
    "          validation_data=(X_test3, y_test_cat))\n",
    "\n",
    "\n",
    "model3.save('vgg19_backbone_50epochs.hdf5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
